{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a25678c9993c1c2bbf0167f2ff03c982",
     "grade": false,
     "grade_id": "header-instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tips\n",
    "- To avoid unpleasant surprises, I suggest you _run all cells in their order of appearance_ (__Cell__ $\\rightarrow$ __Run All__).\n",
    "\n",
    "\n",
    "- If the changes you've made to your solution don't seem to be showing up, try running __Kernel__ $\\rightarrow$ __Restart & Run All__ from the menu.\n",
    "\n",
    "\n",
    "- Before submitting your assignment, make sure everything runs as expected. First, restart the kernel (from the menu, select __Kernel__ $\\rightarrow$ __Restart__) and then **run all cells** (from the menu, select __Cell__ $\\rightarrow$ __Run All__).\n",
    "\n",
    "## Reminder\n",
    "\n",
    "- Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name, UA email, and collaborators below:\n",
    "\n",
    "\n",
    "\n",
    "Several of the cells in this notebook are **read only** to ensure instructions aren't unintentionally altered.  \n",
    "\n",
    "If you can't edit the cell, it is probably intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Wenmo Sun\"\n",
    "# University of Arizona email address\n",
    "EMAIL = \"wmsun@email.arizona.edu\"\n",
    "# Names of any collaborators.  Write N/A if none.\n",
    "COLLABORATORS = \"NA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0783621da2f047c6360f2ec0d56f121c",
     "grade": false,
     "grade_id": "cell-e35b85c2416e40f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Scratchpad\n",
    "\n",
    "You are welcome to create new cells (see the __Cell__ menu) to experiment and debug your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c80ac423030cfa372644d7cd456061af",
     "grade": false,
     "grade_id": "cell-955f8133afe96b26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e07f9ac61f4be6a57b6961cde23a6d58",
     "grade": false,
     "grade_id": "cell-a2292c2fbc4cf52e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mini Python tutorial\n",
    "\n",
    "This course uses Python 3.8.\n",
    "\n",
    "Below is a very basic (and incomplete) overview of the Python language... \n",
    "\n",
    "For those completely new to Python, [this section of the official documentation may be useful](https://docs.python.org/3.8/library/stdtypes.html#common-sequence-operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfcd9f827d4855d02514b2e54ba32077",
     "grade": false,
     "grade_id": "cell-d6593132353238c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      "[2, 3, 4, 5]\n",
      "[2]\n",
      "hello, Josuke!\n",
      "Howdy, partner!\n",
      "13\n",
      "Hi, Fred!\n",
      "[('radical', 4), ('analysis', 7), ('bighorn', 12), ('bounce', 32)]\n",
      "[('analysis', 7), ('bighorn', 12), ('bounce', 32), ('radical', 4)]\n"
     ]
    }
   ],
   "source": [
    "# This is a comment.  \n",
    "# Any line starting with # will be interpreted as a comment\n",
    "\n",
    "# this is a string assigned to a variable\n",
    "greeting = \"hello\"\n",
    "\n",
    "# If enclosed in triple quotes, strings can also be multiline:\n",
    "\n",
    "\"\"\"\n",
    "I'm a multiline\n",
    "string.\n",
    "\"\"\"\n",
    "\n",
    "# let's use a for loop to print it letter by letter\n",
    "for letter in greeting:\n",
    "    print(letter)\n",
    "    \n",
    "# Did you notice the indentation there?  Whitespace matters in Python!\n",
    "\n",
    "# here's a list of integers\n",
    "\n",
    "numbers = [1, 2, 3, 4]\n",
    "\n",
    "# let's add one to each number using a list comprehension\n",
    "# and assign the result to a variable called res\n",
    "# list comprehensions are used widely in Python (they're very Pythonic!)\n",
    "\n",
    "res = [num + 1 for num in numbers]\n",
    "\n",
    "# let's confirm that it worked\n",
    "print(res)\n",
    "\n",
    "# now let's try spicing things up using a conditional to filter out all values greater than or equal to 3...\n",
    "print([num for num in res if not num >= 3])\n",
    "\n",
    "# Python 3.7 introduced \"f-strings\" as a convenient way of formatting strings using templates\n",
    "# For example ...\n",
    "name = \"Josuke\"\n",
    "\n",
    "print(f\"{greeting}, {name}!\")\n",
    "\n",
    "# f-strings are f-ing convenient!\n",
    "\n",
    "\n",
    "# let's look at defining functions in Python..\n",
    "\n",
    "def greet(name):\n",
    "    print(f\"Howdy, {name}!\")\n",
    "\n",
    "# here's how we call it...\n",
    "\n",
    "greet(\"partner\")\n",
    "\n",
    "# let's add a description of the function...\n",
    "\n",
    "def greet(name):\n",
    "    \"\"\"\n",
    "    Prints a greeting given some name.\n",
    "    \n",
    "    :param name: the name to be addressed in the greeting\n",
    "    :type name: str\n",
    "    \n",
    "    \"\"\"\n",
    "    print(f\"Howdy, {name}!\")\n",
    "    \n",
    "# I encourage you to use docstrings!\n",
    "\n",
    "# Python introduced support for optional type hints in v3.5.\n",
    "# You can read more aobut this feature here: https://docs.python.org/3.8/library/typing.html\n",
    "# let's give it a try...\n",
    "def add_six(num: int) -> int:\n",
    "    return num + 6\n",
    "\n",
    "# this should print 13\n",
    "print(add_six(7))\n",
    "\n",
    "# Python also has \"anonymous functions\" (also known as \"lambda\" functions)\n",
    "# take a look at the following code:\n",
    "\n",
    "greet_alt = lambda name: print(f\"Hi, {name}!\")\n",
    "\n",
    "greet_alt(\"Fred\")\n",
    "\n",
    "# lambda functions are often passed to other functions\n",
    "# For example, they can be used to specify how a sequence should be sorted\n",
    "# let's sort a list of pairs by their second element\n",
    "pairs = [(\"bounce\", 32), (\"bighorn\", 12), (\"radical\", 4), (\"analysis\", 7)]\n",
    "# -1 is last thing in some sequence, -2 is the second to last thing in some seq, etc.\n",
    "print(sorted(pairs, key=lambda pair: pair[-1]))\n",
    "\n",
    "# we can sort it by the first element instead\n",
    "# NOTE: python indexing is zero-based\n",
    "print(sorted(pairs, key=lambda pair: pair[0]))\n",
    "\n",
    "# You can learn more about other core data types and their methods here: \n",
    "# https://docs.python.org/3.8/library/stdtypes.html\n",
    "\n",
    "# Because of its extensive standard library, Python is often described as coming with \"batteries included\".  \n",
    "# Take a look at these \"batteries\": https://docs.python.org/3.8/library/\n",
    "\n",
    "# You now know enough to complete this homework assignment (or at least where to look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9833c1ce55cdc8f894b287df328ab677",
     "grade": false,
     "grade_id": "test-imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterator, Iterable, List, Tuple, Text, Union\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import spmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "977e8748cd34c9d1bcdec0b84601b983",
     "grade": false,
     "grade_id": "needed-imports",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Add needed imports here!\n",
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f9a7e22714cd4819e5c3540627384cd",
     "grade": false,
     "grade_id": "random-seed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# An NDArray can either be a numpy array (np.ndarray) or a sparse matrix (spmatrix)\n",
    "NDArray = Union[np.ndarray, spmatrix]\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a90496aa4958e8d071d296eefc9a2bdb",
     "grade": false,
     "grade_id": "cell-f4a4e53967b8f695",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment overview\n",
    "\n",
    "In this assignment, you'll use a binomial logistic regression classifier with $n$-gram features to categorize SMS messages as **SPAM** or **NOT SPAM**.  \n",
    "\n",
    "You will not be required to implement logistic regression from scratch.  Instead, you may use the `scikit-learn` implementation.  Be sure to carefully read the comments in the code skeleton provided.  To earn full credit, all tests must pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7c72a4e0f790e0ca25b37d3db6139db",
     "grade": false,
     "grade_id": "md-read-smsspam",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## `.read_smsspam()`\n",
    "\n",
    "First we'll need data for training and evaluating our classifier.\n",
    "\n",
    "Complete the function below which takes a path to a file (stored under `data` in the docker image) and returns a sequence of (label, text) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7257ac60f5c5b2fcb7413e967cda841",
     "grade": false,
     "grade_id": "code-read-smsspam",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_smsspam(smsspam_path: Text) -> Iterator[Tuple[Text, Text]]:\n",
    "    \"\"\"\n",
    "    Generates (label, text) tuples from the lines in an SMSSpam file.\n",
    "\n",
    "    SMSSpam files contain one message per line. Each line is composed of a label\n",
    "    (ham or spam), a tab character, and the text of the SMS. Here are some\n",
    "    examples:\n",
    "\n",
    "      spam\t85233 FREE>Ringtone!Reply REAL\n",
    "      ham\tI can take you at like noon\n",
    "      ham\tWhere is it. Is there any opening for mca.\n",
    "\n",
    "    :param smsspam_path: The path of an SMSSpam file, formatted as above.\n",
    "    :return: An iterator over (label, text) tuples.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "#     res = []\n",
    "#     with open(smsspam_path) as doc:\n",
    "#         for line in doc:\n",
    "#             temp = []\n",
    "#             temp.append(line.strip().split(\"\\t\")[0])\n",
    "#             temp.append(line.strip().split(\"\\t\")[1])\n",
    "#             res.append(temp)\n",
    "            \n",
    "    with open(smsspam_path) as doc:\n",
    "        lines = [line.strip().split(\"\\t\") for line in doc]\n",
    "    return iter([(element[0], element[1]) for element in lines])\n",
    "    \n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "090962f0ecf8cb76ed91165eee0dbdc3",
     "grade": false,
     "grade_id": "md-test-read-smsspam",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test `.read_smsspam()` (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cd2867872d0662f97fc4f24bb99efb6",
     "grade": true,
     "grade_id": "test-read-smsspam",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# keep a counter here (instead of enumerate) in case the iterator is empty\n",
    "count = 0\n",
    "for example in read_smsspam(\"data/smsspam/SMSSpamCollection.train\"):\n",
    "\n",
    "    # make sure the right shape is returned\n",
    "    assert len(example) == 2\n",
    "    label, text = example\n",
    "\n",
    "    # make sure the label is one of the expected two\n",
    "    assert label in { \"ham\", \"spam\" }\n",
    "\n",
    "    count += 1\n",
    "\n",
    "# You should find exactly 3345 pairs in the training partition of the data\n",
    "assert count == 3345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d81129e4c91af384bdc832d4d1b7b75d",
     "grade": false,
     "grade_id": "md-texttofeatures",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## `TextToFeatures`\n",
    "\n",
    "Using the provided skeleton, complete the class `TextToFeatures` to transform text (documents) into real-valued features derived from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7751ca6573551d429a33f41243cdc2da",
     "grade": false,
     "grade_id": "code-texttofeatures",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TextToFeatures:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes an object for converting texts to features.    \n",
    "        \"\"\"\n",
    "        \n",
    "        # HINT: store a you may want to use a sklearn vectorizer.\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        self.vectorizer = TfidfVectorizer(ngram_range = (1, 2), token_pattern = r'\\b\\w+\\b')\n",
    "        \n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def fit(self, training_texts: Iterable[Text]) -> None:\n",
    "        \"\"\"\n",
    "        Fits (\"trains\") a TextToFeature instance on a collection of documents.\n",
    "        \n",
    "        The provided training texts are analyzed to determine the vocabulary, \n",
    "        i.e., all feature values that the converter will support. \n",
    "        Each such feature value will be associated with a unique integer index \n",
    "        that may later be accessed via the .index() method.\n",
    "\n",
    "        It is up to the implementer exactly what features to produce from a\n",
    "        text, but the features will always include some single words and some\n",
    "        multi-word expressions (e.g., \"need\" and \"to you\").\n",
    "        \n",
    "        \n",
    "        docs = [\n",
    "            \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "            \"The IRS has been trying to reach you.\",\n",
    "            \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "            \"Logan I'd like to add you to my professional network on LinkedIn\",\n",
    "        ]\n",
    "        \n",
    "        t2f = TextToFeatures()\n",
    "        t2f.fit(docs)\n",
    "\n",
    "        :param training_texts: The training texts.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        self.vectorizer.fit(training_texts)\n",
    "        \n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def index(self, feature: Text) -> Union[None, int]:\n",
    "        \"\"\"\n",
    "        Returns the index in the vocabulary of the given feature value.  \n",
    "        If the features isn't present, return None.\n",
    "\n",
    "        :param feature: A feature\n",
    "        :return: The unique integer index associated with the feature or None if not present.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # print(self.vectorizer.get_feature_names())\n",
    "        if feature not in self.vectorizer.get_feature_names():\n",
    "            return None\n",
    "        else:\n",
    "#             print(\"index: \", self.vectorizer.get_feature_names().index(feature))\n",
    "            # print(\"feature names: \", self.vectorizer.get_feature_names())\n",
    "#             print(\"number of features: \", len(self.vectorizer.get_feature_names()))\n",
    "            return self.vectorizer.get_feature_names().index(feature)\n",
    "        \n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def transform(self, texts: Iterable[Text]) -> NDArray:\n",
    "        \"\"\"\n",
    "        Creates a feature matrix from a sequence of texts.\n",
    "        \n",
    "        docs = [\n",
    "            \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "            \"The IRS has been trying to reach you.\",\n",
    "            \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "            \"I'd like to add you to my professional network on LinkedIn\",\n",
    "        ]\n",
    "        \n",
    "        t2f = TextToFeatures()\n",
    "        t2f.fit(docs)\n",
    "\n",
    "        # this produces a NDArray representing our features for the provided doc\n",
    "        t2f.transform([\"Let's meet at Coyote Joe's at 6.\"])\n",
    "\n",
    "\n",
    "        Each row of the matrix corresponds to one of the input texts. The value\n",
    "        at index j of row i is the value in the ith text of the feature\n",
    "        associated with the unique integer j.\n",
    "\n",
    "        It is up to the implementer what the value of a feature that is present\n",
    "        in a text should be, though a common choice is 1. Features that are\n",
    "        absent from a text will have the value 0.\n",
    "\n",
    "        :param texts: A sequence of texts.\n",
    "        :return: A matrix, with one row of feature values for each text.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "#         print(\"to features array\", self.vectorizer.transform(texts).toarray())\n",
    "#         print(\"to features array type\", type(self.vectorizer.transform(texts).toarray()))\n",
    "#         print(\"columns of feature array: \", len(self.vectorizer.transform(texts).toarray()[0]))\n",
    "        return self.vectorizer.transform(texts).toarray()\n",
    "        \n",
    "        # raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c9606eb97271a658b6e05ec97db13fa",
     "grade": false,
     "grade_id": "md-test-texttofeatures",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test features (5 pts)\n",
    "\n",
    "Let's test the behavior of your implementation of `TextToFeatures`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "955468df8034ecd7118b922351f32904",
     "grade": true,
     "grade_id": "test-texttofeatures-1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_texts: List[Text] = [\n",
    "    \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "    \"The IRS has been trying to reach you.\",\n",
    "    \"You won't believe what in this doc.  Click here to find out!\",\n",
    "    \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "    \"Logan I'd like to add you to my professional network on LinkedIn\",\n",
    "]\n",
    "    \n",
    "t2f = TextToFeatures()\n",
    "t2f.fit(training_texts)\n",
    "\n",
    "features = t2f.transform([\"Is Bill in your professional network?\"])\n",
    "# ensure there is one row of features for each sentence\n",
    "assert features.shape[0] == 1\n",
    "# ensure there are nonzero values for some selected unigram and bigram features\n",
    "assert t2f.index(\"reach\") is not None\n",
    "\n",
    "# if a feature wasn't observed during training, it should not have an index\n",
    "assert t2f.index(\"strawberry kangaroos\") is None\n",
    "assert t2f.index(\"Jason Mendoza\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a90a2727bb82503fc6e5019d4209b34e",
     "grade": true,
     "grade_id": "test-texttofeatures-2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get the texts from the training data\n",
    "examples: Iterable[Tuple[str, str]]  = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "training_texts: List[str]            = [text for _, text in examples]\n",
    "\n",
    "# create the feature extractor from the training texts\n",
    "t2f = TextToFeatures()\n",
    "t2f.fit(training_texts)\n",
    "\n",
    "# extract features for some made-up sentences\n",
    "features = t2f.transform([\n",
    "    \"There are some things that I need to send to you.\",\n",
    "    \"Hello!\"\n",
    "])\n",
    "\n",
    "# make sure there is one row of features for each sentence\n",
    "assert len(features.shape) == 2\n",
    "n_rows, n_cols = features.shape\n",
    "assert n_rows == 2\n",
    "\n",
    "# make sure there are nonzero values for some selected unigram and bigram\n",
    "# features in the first sentence\n",
    "indices = [t2f.index(f) for f in [\"need\", \"to you\"]]\n",
    "assert len(set(indices)) > 1\n",
    "row_indices, col_indices = features[:, indices].nonzero()\n",
    "assert np.all(row_indices == 0)\n",
    "assert len(col_indices) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TextToLabels`\n",
    "Using the provided skeleton, complete the class `TextToLabels` to map class labels (strings) to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fbaab7c6286a32261319404ea3805e9",
     "grade": false,
     "grade_id": "code-texttolabels",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TextToLabels:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes an object for converting texts to labels.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "    def fit(self, training_labels: Iterable[Text]) -> None:\n",
    "        \"\"\"\n",
    "        Assigns each distinct label a unique integer.\n",
    "        \n",
    "        \n",
    "        Training labels are analyzed to determine the vocabulary, \n",
    "        i.e., all labels that the converter will support. \n",
    "        Each such label will be associated with a unique integer index \n",
    "        that may later be accessed via the .index() method.\n",
    "\n",
    "        :param training_labels: The training labels.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        self.le.fit(training_labels)\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "    def index(self, label: Text) -> Union[None, int]:\n",
    "        \"\"\"Returns the index in the vocabulary of the given label.\n",
    "\n",
    "        :param label: A label\n",
    "        :return: The unique integer index associated with the label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        if label not in list(self.le.classes_):\n",
    "            return None\n",
    "        else:\n",
    "            return list(self.le.classes_).index(label)\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def transform(self, labels: Iterable[Text]) -> NDArray:\n",
    "        \"\"\"\n",
    "        Creates a label vector from a sequence of labels.\n",
    "\n",
    "        Each entry in the vector corresponds to one of the input labels. The\n",
    "        value at index j is the unique integer associated with the jth label.\n",
    "\n",
    "        :param labels: A sequence of labels.\n",
    "        :return: A vector, with one entry for each label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "#         print(\"text to labels: \", self.le.transform(labels))\n",
    "#         print(\"text to labels type: \", type(self.le.transform(labels)))\n",
    "        return self.le.transform(labels)\n",
    "        \n",
    "        # raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def __contains__(self, label: Text) -> bool:\n",
    "        \"\"\"\n",
    "        Special \"dunder\" method to check if a label is known to the TextToLabels instance.\n",
    "        \n",
    "        labeler = TextToLabels()\n",
    "        labeler.fit([\"POSITIVE\", \"NEGATIVE\"])\n",
    "\n",
    "        # should be True:\n",
    "        \"POSITIVE\" in labeler \n",
    "        \n",
    "        # should be False:\n",
    "        \"MBOP\" in labeler\n",
    "        \n",
    "        :return: True if the label was seen in the training data; False otherwise\n",
    "        \"\"\"\n",
    "        # NOTE: you do not need to change this if you've implemented .index() correctly!\n",
    "        return False if self.index(label) is None else True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88f44e011390d5de39183a7ca5d80865",
     "grade": false,
     "grade_id": "md-test-texttolabels",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test labels (5pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46a9acdc3680ae11eae0bb7070762735",
     "grade": true,
     "grade_id": "test-texttolabels-1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_labels = [\"SPAM\", \"NOT_SPAM\"]\n",
    "lbl_encoder     = TextToLabels()\n",
    "lbl_encoder.fit(training_labels)\n",
    "\n",
    "assert \"SPAM\" in lbl_encoder\n",
    "assert lbl_encoder.index(\"SPAM\") is not None\n",
    "\n",
    "# this label wasn't seen in the training data labels\n",
    "assert \"DISSERTATION\" not in lbl_encoder\n",
    "assert lbl_encoder.index(\"DISSERTATION\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "297f9ee32baa3ab146ebdc9b7f4a79b0",
     "grade": true,
     "grade_id": "test-texttolabels-2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text to labels:  [0 1 1]\n",
      "text to labels type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "def test_labels():\n",
    "    # get the texts from the training data\n",
    "    examples = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "    labels = [label for label, _ in examples]\n",
    "\n",
    "    # create the label encoder from the training texts\n",
    "    lbl_encoder = TextToLabels()\n",
    "    lbl_encoder.fit(labels)\n",
    "\n",
    "    # just a simple convenience function to use for testing...\n",
    "    to_labels = lambda labels: lbl_encoder.transform(labels)\n",
    "    \n",
    "    # make sure that some sample labels are encoded as expected\n",
    "    ham_index = lbl_encoder.index(\"ham\")\n",
    "    spam_index = lbl_encoder.index(\"spam\")\n",
    "    assert ham_index != spam_index\n",
    "    assert np.all(\n",
    "        to_labels([\"ham\", \"spam\", \"spam\"]) == [ham_index, spam_index, spam_index]\n",
    "    )\n",
    "\n",
    "test_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3343935439326da0eda803a66ea6bbec",
     "grade": false,
     "grade_id": "cell-12ff0ecbb3bbcf93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# `Classifier`\n",
    "Using the provided skeleton, complete the class `Classifier` which will use `sklearn`'s logistic regression classifier.  You will implement the `train` and `predict` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87d7be9c626dd81f9feb533d71c8bbbc",
     "grade": false,
     "grade_id": "cell-b30da2f58a08c088",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initalizes a logistic regression classifier.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        self.clf = LogisticRegression(penalty='l2', C=1e2, class_weight='balanced', solver='liblinear')\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "    def train(self, features: NDArray, labels: NDArray) -> None:\n",
    "        \"\"\"\n",
    "        Trains the classifier using the given training examples.\n",
    "\n",
    "        :param features: A feature matrix, where each row represents a text.\n",
    "        Such matrices will typically be generated via TextToFeatures.\n",
    "        :param labels: A label vector, where each entry represents a label.\n",
    "        Such vectors will typically be generated via TextToLabels.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        self.clf.fit(features, labels)\n",
    "        # raise NotImplementedError()\n",
    "    \n",
    "    # just an alias for \"train\"\n",
    "    # fit = train\n",
    "    \n",
    "    def predict(self, features: NDArray) -> NDArray:\n",
    "        \"\"\"Makes predictions for each of the given examples.\n",
    "\n",
    "        :param features: A feature matrix, where each row represents a text.\n",
    "        Such matrices will typically be generated via TextToFeatures.\n",
    "        :return: A prediction vector, where each entry represents a label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "#         print(\"features for prediction: \", features)\n",
    "#         print(\"predicted features: \", self.clf.predict(features))\n",
    "#         print(\"the type of predicted features: \", type(self.clf.predict(features)))\n",
    "        # forgot to add return and it caused the NoneType issue in the test.\n",
    "        return self.clf.predict(features)\n",
    "        #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1deb43374a951cea20982c9325aa112c",
     "grade": false,
     "grade_id": "md-min-f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Min F1 Score (4pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f67c08a1351d36d8b3a48e785f7f6ca",
     "grade": true,
     "grade_id": "test-predictions",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text to labels:  [0 0 1 ... 0 0 0]\n",
      "text to labels type:  <class 'numpy.ndarray'>\n",
      "features for prediction:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "predicted features:  [0 0 0 ... 0 0 0]\n",
      "the type of predicted features:  <class 'numpy.ndarray'>\n",
      "text to labels:  [0 0 0 ... 0 0 0]\n",
      "text to labels type:  <class 'numpy.ndarray'>\n",
      "\n",
      "95.0% F1 and 98.7% accuracy on SMSSpam development data\n"
     ]
    }
   ],
   "source": [
    "def test_prediction(min_f1=0.89, min_accuracy=0.97):\n",
    "    # get texts and labels from the training data\n",
    "    train_examples = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "    train_labels, train_texts = zip(*train_examples)\n",
    "\n",
    "    # get texts and labels from the development data\n",
    "    dev_examples = read_smsspam(\"data/smsspam/SMSSpamCollection.devel\")\n",
    "    dev_labels, dev_texts = zip(*dev_examples)\n",
    "\n",
    "    # fit/\"train\" the feature extractor and label encoder\n",
    "    to_features = TextToFeatures()\n",
    "    to_features.fit(train_texts)\n",
    "    to_labels   = TextToLabels()\n",
    "    to_labels.fit(train_labels)\n",
    "\n",
    "    # train the classifier on the training data\n",
    "    clf = Classifier()\n",
    "    clf.train(to_features.transform(train_texts), to_labels.transform(train_labels))\n",
    "\n",
    "    # make predictions on the development data\n",
    "    predicted_indices = clf.predict(to_features.transform(dev_texts))\n",
    "    assert np.array_equal(predicted_indices, predicted_indices.astype(bool))\n",
    "\n",
    "    # measure performance of predictions\n",
    "    dev_indices   = to_labels.transform(dev_labels)\n",
    "    spam_label    = to_labels.index(\"spam\")\n",
    "    f1            = f1_score(dev_indices, predicted_indices, pos_label=spam_label)\n",
    "    accuracy      = accuracy_score(dev_indices, predicted_indices)\n",
    "\n",
    "    print(f\"\\n{f1:.1%} F1 and {accuracy:.1%} accuracy on SMSSpam development data\")\n",
    "\n",
    "    # make sure that performance is adequate\n",
    "    assert f1 > min_f1\n",
    "    assert accuracy > min_accuracy\n",
    "    \n",
    "test_prediction(min_f1=0.89, min_accuracy=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9883f350c5ce553fc21e1d243a17e06",
     "grade": false,
     "grade_id": "md-high-f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## High F1 score (2 pts)\n",
    "\n",
    "Adjust your classifier (ex. features, regularization, etc.) as needed to achieve a minimum F1 score of 0.94."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1f03092c349b837b3419447b85859e4",
     "grade": true,
     "grade_id": "test-high-performance",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text to labels:  [0 0 1 ... 0 0 0]\n",
      "text to labels type:  <class 'numpy.ndarray'>\n",
      "features for prediction:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "predicted features:  [0 0 0 ... 0 0 0]\n",
      "the type of predicted features:  <class 'numpy.ndarray'>\n",
      "text to labels:  [0 0 0 ... 0 0 0]\n",
      "text to labels type:  <class 'numpy.ndarray'>\n",
      "\n",
      "95.0% F1 and 98.7% accuracy on SMSSpam development data\n"
     ]
    }
   ],
   "source": [
    "test_prediction(min_f1=0.94, min_accuracy=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
